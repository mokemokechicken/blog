<!doctype html><html class=no-js lang=ja>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<title>HuggingFace で日本語モデルを使ってみる - My First Step</title>
<script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script>
<meta name=description content>
<meta property="og:title" content="HuggingFace で日本語モデルを使ってみる">
<meta property="og:description" content="Bert など事前学習済み日本語モデルを環境構築からMaskされた単語の推定タスクの最初の出力までを行いました。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blog.my-first-step.info/ja/tech/ml/nlp-japanese/hugging_face-first_step/"><meta property="article:section" content="tech">
<meta property="article:published_time" content="2021-12-23T00:00:00+00:00">
<meta property="article:modified_time" content="2021-12-23T00:00:00+00:00"><meta property="og:site_name" content="My First Step">
<meta itemprop=name content="HuggingFace で日本語モデルを使ってみる">
<meta itemprop=description content="Bert など事前学習済み日本語モデルを環境構築からMaskされた単語の推定タスクの最初の出力までを行いました。"><meta itemprop=datePublished content="2021-12-23T00:00:00+00:00">
<meta itemprop=dateModified content="2021-12-23T00:00:00+00:00">
<meta itemprop=wordCount content="1547">
<meta itemprop=keywords content="ML,NLP,BERT,transformers,HuggingFace,Python,">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=dns-prefetch href=//fonts.googleapis.com>
<link rel=dns-prefetch href=//fonts.gstatic.com>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
<link rel=stylesheet href=/css/style.css>
<link rel=stylesheet href=/css/my-style.css>
<link rel="shortcut icon" href=/favicon.ico>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SV0KGCR6DC"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-SV0KGCR6DC',{anonymize_ip:!1})}</script>
</head>
<body class=body>
<div class="container container--outer">
<header class=header>
<div class="container header__container">
<div class=logo>
<a class=logo__link href=/ja/ title="My First Step" rel=home>
<div class="logo__item logo__text">
<div class=logo__title>My First Step</div>
</div>
</a>
</div>
<div class=divider></div>
</div>
</header>
<div class="wrapper flex">
<div class=primary>
<main class=main role=main>
<article class=post>
<header class=post__header>
<h1 class=post__title>HuggingFace で日本語モデルを使ってみる</h1>
<p class=post__lead>事前学習済みの日本語モデルが数行書くだけで試せる時代になったようです</p>
<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2021-12-23T00:00:00Z>2021-12-23</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/ja/categories/ml/ rel=category>ML</a>
</span>
</div></div>
</header>
<div class="post__toc toc">
<div class=toc__title>目次</div>
<div class=toc__menu>
<nav id=TableOfContents>
<ul>
<li><a href=#環境構築>環境構築</a>
<ul>
<li><a href=#前提環境>前提環境</a></li>
<li><a href=#プロジェクト環境構築>プロジェクト環境構築</a></li>
</ul>
</li>
<li><a href=#動かしてみる>動かしてみる</a>
<ul>
<li><a href=#サンプルコード>サンプルコード</a></li>
<li><a href=#いろいろ遊べる部分>いろいろ遊べる部分</a></li>
</ul>
</li>
<li><a href=#さいごに>さいごに</a></li>
<li><a href=#reference>Reference</a></li>
</ul>
</nav>
</div>
</div><div class="content post__content clearfix">
<p>クロスワードパズルとかNLPでできるのかなーとちょっと思ったので、最近流行りの HuggingFace を試してみました。
どうやら事前学習済みの日本語モデルが数行書くだけで試せる時代になったようです。</p>
<h2 id=環境構築>環境構築</h2>
<p>今回は <code>pyenv</code> を使って <code>Python3.9</code> 系に <code>poetry</code> を使って色々 Install していきます。</p>
<h3 id=前提環境>前提環境</h3>
<ul>
<li>MacBook Pro(M1), OS: Monterey(12.0.1)</li>
<li><code>brew</code> は Install済みとします</li>
<li><code>pyenv</code>: <code>2.2.2</code>
<ul>
<li>もしまだ Install されていなければ、 <code>brew install pyenv</code> で Install できます</li>
</ul>
</li>
<li><code>Python</code>: <code>3.9.9</code>
<ul>
<li>もしまだ Install されていなければ <code>pyenv install 3.9.9</code> で Install できます</li>
</ul>
</li>
</ul>
<h3 id=プロジェクト環境構築>プロジェクト環境構築</h3>
<p>まず ディレクトリ を作って、<code>Python3.9.9</code> を使うように指定して、<code>poetry</code> の初期化をします。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir my_bert
cd my_bert
pyenv local 3.9.9
poetry init -n --python <span style=color:#e6db74>&#39;&gt;=3.9,&lt;3.10&#39;</span>
</code></pre></div><p>上記のように <code>--python '>=3.9,&lt;3.10'</code> としておくのは大事で、そうしないと <code>poetry add numpy</code> がバージョン互換性のために失敗してしまいます。</p>
<hr>
<p><code>numpy</code>, <code>torch</code>, <code>transformers</code> をInstallします。
ちょっと前までは M1 Mac にこれらをInstallするのが難航したものですが、今は簡単に入りますね。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>poetry add numpy torch transformers
</code></pre></div><hr>
<p>今回使う <a href=https://huggingface.co/cl-tohoku/bert-base-japanese-char-v2>bert-base-japanese-char-v2</a> が
<code>mecab</code>, <code>fugashi</code>, <code>unidic_lite</code> を必要とするので、これもInstallします。
どの言語モデルがどういうライブラリを要求するかは色々あるので、
実際は「何かエラーが出たら追加でInstallする」という感じになると思います。</p>
<p>※ わざわざ再現するのもあれなので最初からInstallします。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>brew install mecab
poetry add fugashi unidic_lite
</code></pre></div><p>最終的にInstallされていたバージョンは以下の通りです。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=color:#a6e22e>numpy</span> = <span style=color:#e6db74>&#34;^1.21.5&#34;</span>
<span style=color:#a6e22e>torch</span> = <span style=color:#e6db74>&#34;^1.10.1&#34;</span>
<span style=color:#a6e22e>transformers</span> = <span style=color:#e6db74>&#34;^4.15.0&#34;</span>
<span style=color:#a6e22e>fugashi</span> = <span style=color:#e6db74>&#34;^1.1.1&#34;</span>
<span style=color:#a6e22e>unidic-lite</span> = <span style=color:#e6db74>&#34;^1.0.8&#34;</span>
</code></pre></div><h2 id=動かしてみる>動かしてみる</h2>
<p><a href=https://huggingface.co/cl-tohoku/bert-base-japanese-char-v2>bert-base-japanese-char-v2</a> は、
東北大学が公開してくれている学習済みモデルです。
ちょっと変わっているのは「辞書に載っているような単語単位で学習したモデル」ではなく「文字単位で学習したモデル」というところです。</p>
<p>なので例えば、文章の一部分を隠して推測させるタスク(
<a href=https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/pipelines#transformers.FillMaskPipeline>fill-mask</a>)
では、１文字分の予測結果を返すことになります。
クロスワードパズルとかできそうですね。</p>
<h3 id=サンプルコード>サンプルコード</h3>
<p>以下のようなコードで 「私は◯です。」 の 「◯」の部分を予測させることができます。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># play.py</span>
<span style=color:#f92672>from</span> pprint <span style=color:#f92672>import</span> pprint

<span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModelForMaskedLM, pipeline
<span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> BertForMaskedLM, BertJapaneseTokenizer  <span style=color:#75715e># for type complemention</span>

tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#34;cl-tohoku/bert-base-japanese-char-v2&#34;</span>)  <span style=color:#75715e># type: BertJapaneseTokenizer</span>
model <span style=color:#f92672>=</span> AutoModelForMaskedLM<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#34;cl-tohoku/bert-base-japanese-char-v2&#34;</span>)  <span style=color:#75715e># type: BertForMaskedLM</span>
pipe <span style=color:#f92672>=</span> pipeline(<span style=color:#e6db74>&#34;fill-mask&#34;</span>, model<span style=color:#f92672>=</span>model, tokenizer<span style=color:#f92672>=</span>tokenizer)

MASK <span style=color:#f92672>=</span> tokenizer<span style=color:#f92672>.</span>mask_token
text <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;今日は休みなので、私は</span><span style=color:#e6db74>{</span>MASK<span style=color:#e6db74>}</span><span style=color:#e6db74>です。&#34;</span>
pprint(pipe(text, top_k<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>))
</code></pre></div><p>コマンドラインから</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>poetry run python play.py
</code></pre></div><p>などで実行してみると、以下のようになりました。</p>
<pre tabindex=0><code>[{'score': 0.2861271798610687,
  'sequence': '今 日 は 休 み な の で 、 私 は 嫌 で す 。',
  'token': 1941,
  'token_str': '嫌'},
 {'score': 0.13725848495960236,
  'sequence': '今 日 は 休 み な の で 、 私 は 朝 で す 。',
  'token': 2821,
  'token_str': '朝'},
 {'score': 0.07323182374238968,
  'sequence': '今 日 は 休 み な の で 、 私 は 暇 で す 。',
  'token': 2773,
  'token_str': '暇'}]
</code></pre><p>まあ、３つ目くらいが妥当ですかね&mldr;</p>
<h3 id=いろいろ遊べる部分>いろいろ遊べる部分</h3>
<ul>
<li>言語モデルは <a href=https://huggingface.co/models>Hugging Face Models</a> の中から選んで指定できます。ただし、モデルによって必要なライブラリが違うので、エラ
ーが出たらその名前から適当にInstallしてみると良いでしょう。キーワードはたいていモデル説明ページのドキュメントにも書いてあることが多いです。</li>
<li><code>top_k=3</code> の部分で上位いくつの結果を返すかを指定できます。</li>
<li><code>pipe(text, targets=["嘘", "馬", "前", "橘", "上"])</code> というように <code>targets</code> で指定した単語のscoreを返してくれます。
<pre tabindex=0><code>[{'score': 0.007146810181438923,
'sequence': '今 日 は 休 み な の で 、 私 は 嘘 で す 。',
'token': 1681,
'token_str': '嘘'},
{'score': 0.004257831256836653,
'sequence': '今 日 は 休 み な の で 、 私 は 前 で す 。',
'token': 1402,
'token_str': '前'},
{'score': 0.0002205580531153828,
'sequence': '今 日 は 休 み な の で 、 私 は 上 で す 。',
'token': 1037,
'token_str': '上'},
{'score': 0.00012557016452774405,
'sequence': '今 日 は 休 み な の で 、 私 は 馬 で す 。',
'token': 5741,
'token_str': '馬'},
{'score': 2.5849765279417625e-06,
'sequence': '今 日 は 休 み な の で 、 私 は 橘 で す 。',
'token': 3049,
'token_str': '橘'}]
</code></pre></li>
<li>色々な言語タスクに対応した <code>pipeline</code> があって、それらはこんな感じで簡単に使えます。各pipeline の説明は、<a href=https://note.com/npaka/n/n5bb043191cc9>この方のNote</a> がとてもわかりやすかったです。</li>
</ul>
<h2 id=さいごに>さいごに</h2>
<p>使うだけならここまでお手軽に使えるようです。
あとは超高精度な言語モデルが一般公開されれば&mldr;</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=https://huggingface.co/>Hugging Face</a></li>
<li><a href=https://huggingface.co/docs/transformers/main_classes/pipelines>pipeline</a></li>
</ul>
</div>
<footer class=post__footer>
<div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg>
<ul class=tags__list>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/ml/ rel=tag>ML</a>
</li>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/nlp/ rel=tag>NLP</a>
</li>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/bert/ rel=tag>BERT</a>
</li>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/transformers/ rel=tag>transformers</a>
</li>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/huggingface/ rel=tag>HuggingFace</a>
</li>
<li class=tags__item>
<a class="tags__link btn" href=/ja/tags/python/ rel=tag>Python</a>
</li>
</ul>
</div>
</footer>
</article>
</main>
</div>
</div>
<footer class=footer>
<div class="container footer__container flex">
<div class=footer__links>
<a class=footer__link href=/ja/etc/my_first_step/>このBlogについて</a>
</div>
<div class=footer__copyright>
&copy; 2021 Mokemokechicken.
<span class=footer__copyright-credits>このサイトは <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> と <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> テーマで生成されています。</span>
</div>
</div>
</footer>
</div>
<script async defer src=/js/menu.js></script>
</body>
</html>